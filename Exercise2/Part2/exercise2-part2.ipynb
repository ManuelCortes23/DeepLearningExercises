{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22db81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebe8de",
   "metadata": {},
   "source": [
    "## Exercise 2, part 2\n",
    "\n",
    "We build a CNN where both the input and the output are images (dogs vs cats) https://www.kaggle.com/c/dogs-vs-cats\n",
    "\n",
    "Goal: The dataloader adds random noise to the image, and the network task is to remove that noise, recovering the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213ac0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/z90tvet2q97n350/cats.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27040ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec1331b",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "You don't need to write it, just look at it. For every picture of a cat, it adds a random noise to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cats_dataloader import CatsWithNoiseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I divide 80% of images to be our training set and 20% our validation set\n",
    "\n",
    "train_ds = CatsWithNoiseDataset('cats.npy',0,800)\n",
    "valid_ds = CatsWithNoiseDataset('cats.npy',800,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_ds[100]\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(6,3),dpi=150)\n",
    "\n",
    "ax[0].imshow(y[0],cmap='gist_yarg',vmin=0,vmax=1)\n",
    "ax[1].imshow(x[0],cmap='gist_yarg',vmin=0,vmax=1)\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877528c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4, memory problem otherwise (but play around with it)\n",
    "\n",
    "training_dataloader = DataLoader(train_ds,batch_size=4,shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96644959",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in training_dataloader:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32852135",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv2d(input channel, output channel, convolutional filter size)\n",
    "# padding needs to be tuned in a way that output and input coincide\n",
    "\n",
    "conv_layer = nn.Conv2d(1,50,3,padding = 1)\n",
    "\n",
    "print(x.shape, conv_layer(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8820199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNorm2d It takes as input a batch with shape (N, input_size) \n",
    "# and normalizes each \"column\" in the input batch to have \n",
    "# mean 0 and variance 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e3c829",
   "metadata": {},
   "source": [
    "We need to build a model that takes the images as input and outputs an image of the same size.\n",
    "\n",
    "You can find an example of a model that works below (you can try to build your own). I repeated each block 5 times. Blue boxes correspond to the sequence.\n",
    "\n",
    "* Conv2d\n",
    "* BatchNorm2d\n",
    "* ReLU\n",
    "\n",
    "<div>\n",
    "<img src=\"model_example.jpeg\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "In this way the model will learn the negative value of the noise. Thefore the output will be the sum of the input and the result of the model (a residual block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74655623",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_denoise import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf563449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument indicates number of central layer blocks (5)\n",
    "# output size 25 central layers\n",
    "\n",
    "net = Net()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the output is same size of the input..!!!\n",
    "\n",
    "x.shape, net(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2afe37",
   "metadata": {},
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690624b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The error is MSE, mean square error. We are regressing the correct pixel.\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(dataloader,net):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    n_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            n_batches+=1\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            pred = net(x)\n",
    "            \n",
    "            loss+= loss_func(pred,y).item()\n",
    "            \n",
    "    loss = loss/n_batches      \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c05599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training\n",
    "compute_loss(valid_dataloader,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d1bd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes some time... in the mean time read about google colab, for next exercises we could start CUDA from there\n",
    "\n",
    "if os.path.exist('trained_model.pt'):\n",
    "    net.load_state_dict(torch.load('trained_model.pt',map_location='cpu'))\n",
    "else:\n",
    "    n_epochs = 100\n",
    "\n",
    "    validation_loss_vs_epoch = []\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "\n",
    "    pbar = tqdm( range(n_epochs) )\n",
    "\n",
    "    for epoch in pbar:\n",
    "\n",
    "        if len(validation_loss_vs_epoch) > 1:\n",
    "            print('epoch',epoch,' val loss:'+'{0:.5f}'.format(validation_loss_vs_epoch[-1]) )\n",
    "\n",
    "        net.train() # put the net into \"training mode\"\n",
    "        for x,y in training_dataloader:\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = net(x)\n",
    "            loss = loss_func(pred,y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval() #put the net into evaluation mode\n",
    "\n",
    "        valid_loss =  compute_loss(valid_dataloader,net)\n",
    "\n",
    "        validation_loss_vs_epoch.append(valid_loss)\n",
    "\n",
    "        if len(validation_loss_vs_epoch)==1 or validation_loss_vs_epoch[-2] > validation_loss_vs_epoch[-1]:\n",
    "            torch.save(net.state_dict(), 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training\n",
    "compute_loss(valid_dataloader,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994462f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result with a random validation idx\n",
    "x, y = valid_ds[103]\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(9,3),dpi=150)\n",
    "\n",
    "ax[2].imshow(y[0],cmap='gist_yarg',vmin=0,vmax=1)\n",
    "ax[0].imshow(x[0],cmap='gist_yarg',vmin=0,vmax=1)\n",
    "\n",
    "net.eval()\n",
    "net.cpu()\n",
    "predicted = net( x.unsqueeze(1) )[0][0].data.numpy()\n",
    "\n",
    "ax[1].imshow(predicted,cmap='gist_yarg',vmin=0,vmax=1)\n",
    "\n",
    "ax[0].set_title('Input',fontsize=12)\n",
    "ax[1].set_title('Network output',fontsize=12)\n",
    "ax[2].set_title('Target',fontsize=12)\n",
    "for i in range(3):\n",
    "    ax[i].set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3e8e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f98dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be sure that if you modify a .py file everything is up to date\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8e43d0",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "* create a dataloader to load the galaxy10 dataset\n",
    "* build a classifier with a fully connceted neural network\n",
    "* write a function to compute the classification accuracy of the network prediction\n",
    "* write a training loop and train the model\n",
    "* save the loss and accuracy for both the training dataset and the validation dataset after every epoch\n",
    "* plot the loss and accuracy\n",
    "* save the trained model and the dataset / model in a source code (in a .py file)\n",
    "\n",
    "<b> You have to build a classifier for the galaxy10 dataset. Given a galaxy you have to say which class it belongs to. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7182d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/apl6g5g9svhnfyg/Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46204f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is already divided in training and validation\n",
    "\n",
    "path_to_training_data = 'Dataset/train/'\n",
    "path_to_validation_data = 'Dataset/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa48a2",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The first part of your exercise is to take the following lines and added to the dataloader.py file (in the correct position)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we get a list of the files in the directory\n",
    "\n",
    "import glob\n",
    "\n",
    "# Glob gives you a list of file paths to the images\n",
    "filelist = glob.glob(path_to_training_data+'/*.png')\n",
    "\n",
    "# Print the first 10 entries:\n",
    "filelist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a single image, use the PIL (python image library) function Image\n",
    "from PIL import Image\n",
    "\n",
    "Image.open(filelist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bdaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to turn it into a pytorch tensor, \n",
    "# And flatten it (since we want to train a fully connceted network)\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "img = Image.open(filelist[0])\n",
    "\n",
    "transforms.ToTensor()( img ).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c66177",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We want to normalize our inputs, to have mean pixel value of 0 and standard deviation 1\n",
    "import numpy as np\n",
    "\n",
    "lots_of_images = np.concatenate( [transforms.ToTensor()(Image.open(x)).view(-1) for x in filelist[:1000]] )\n",
    "print(np.mean(lots_of_images),np.std(lots_of_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To determine the class label of an image, just look at its name:\n",
    "\n",
    "filelist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate numerical labels based on the file name\n",
    "# For each element in the filelist it returns the labels\n",
    "\n",
    "import torch\n",
    "\n",
    "labels = np.zeros(len(filelist))\n",
    "\n",
    "for class_i in range(10):\n",
    "    labels[ np.array(['class'+str(class_i) in x for x in filelist]) ] = class_i\n",
    "    \n",
    "# The labels need to be converted to torch.LongTensor for multi-class classification\n",
    "# See the documentation at https://pytorch.org/docs/stable/nn.html#crossentropyloss\n",
    "labels = torch.LongTensor(labels)\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ffe40",
   "metadata": {},
   "source": [
    "You should get something that works now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import CustomDataset\n",
    "\n",
    "# If it doesn't work, I suggest you writing the class here \n",
    "# afterwords copy it in the dataloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79896540",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = CustomDataset(path_to_training_data,transform=True)\n",
    "validation_ds = CustomDataset(path_to_validation_data)\n",
    "\n",
    "some_random_idx = 124\n",
    "training_ds[some_random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets also go ahead and create the data loaders (already a pytorch function),\n",
    "## and set the batch size\n",
    "\n",
    "training_dataloader = DataLoader(training_ds, batch_size = 300, shuffle = True) # random batches\n",
    "valid_dataloader = DataLoader(validation_ds, batch_size = 300)\n",
    "\n",
    "# x should be (batchsize, 69*69) = (300,4761)\n",
    "# y should be (batchsize) = (300)\n",
    "\n",
    "for x,y in training_dataloader:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc2812",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "This should work if dataset and dataloader are set correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(10,5,figsize=(5,10))\n",
    "\n",
    "for class_i in range(10):\n",
    "    idxs = np.where( training_ds.labels == class_i )[0]\n",
    "    idxs = np.random.permutation(idxs)\n",
    "    for plot_i in range(np.min([5,len(idxs)])):\n",
    "\n",
    "        ax[class_i][plot_i].imshow(training_ds[idxs[plot_i]][0].reshape(69,69),cmap='gray')\n",
    "        ax[class_i][plot_i].set_axis_off()\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4e514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the labels\n",
    "\n",
    "plt.hist(training_ds.labels.data.numpy(),bins=np.linspace(0,9,19)-0.25,color='cornflowerblue',ec='k')\n",
    "plt.xticks(np.arange(10))\n",
    "plt.title('class frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bef4d1",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "It's a classifier, it takes a 69 * 69 numbers, and outputs 10 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f48d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import net\n",
    "\n",
    "# create the istance\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b213a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it... it shoule be (batch size, 10) = (300, 10)\n",
    "\n",
    "for x,y in training_dataloader:\n",
    "    break\n",
    "\n",
    "net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be usefull for future exercises, it check if you have cuda. \n",
    "# CUDA is a parallel computing platform and programming model that makes using a GPU for general purpose computing simple\n",
    "# maybe start reading about google colab, it's free and will be useful later\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e716cbc",
   "metadata": {},
   "source": [
    "### Loss and accuracy\n",
    "\n",
    "We want to create a function that will compute the loss and accuracy at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "#It is useful when training a classification problem with C classes. \n",
    "#If provided, the optional argument weight should be a 1D Tensor assigning weight to each of the classes.\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_and_loss(dataloader,net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    loss = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        \n",
    "    net.eval() # When you want to compute loss or accuracy you always have to put the netowrk in evaluation mode\n",
    "    \n",
    "    n_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            n_batches += 1\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "                \n",
    "            pred = net(x)\n",
    "            loss += loss_func(pred,y).item()\n",
    "            pred = torch.argmax(pred,dim=1)\n",
    "\n",
    "            correct += len(torch.where(pred==y)[0])\n",
    "            total += len(y)\n",
    "            \n",
    "    loss = loss/n_batches      \n",
    "    return correct/total, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e05c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy before training, it should be low\n",
    "compute_accuracy_and_loss(training_dataloader,net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a25f6f",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "* Optimizer zero gradient\n",
    "* Output from the network\n",
    "* Computing loss function between output and y\n",
    "* Loss backward\n",
    "* Optimizer step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fc3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "training_loss_vs_epoch = []\n",
    "validation_loss_vs_epoch = []\n",
    "\n",
    "training_acc_vs_epoch = []\n",
    "validation_acc_vs_epoch = []\n",
    "\n",
    "pbar = tqdm( range(n_epochs) )\n",
    "\n",
    "for epoch in pbar:\n",
    "    \n",
    "    if len(validation_loss_vs_epoch) > 1:\n",
    "        pbar.set_description('val acc:'+'{0:.5f}'.format(validation_acc_vs_epoch[-1])+\n",
    "                             ', train acc:'+'{0:.5f}'.format(training_acc_vs_epoch[-1]))\n",
    "    \n",
    "    net.train() # put the net into \"training mode\"\n",
    "    \n",
    "    for x,y in training_dataloader:\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        # compute output of the newtork\n",
    "        # output = ...\n",
    "        # compute the loss function\n",
    "        # loss = loss_func...\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    net.eval() #put the net into evaluation mode\n",
    "    \n",
    "    train_acc, train_loss = compute_accuracy_and_loss(training_dataloader,net)\n",
    "    valid_acc, valid_loss = compute_accuracy_and_loss(valid_dataloader,net)\n",
    "         \n",
    "    training_loss_vs_epoch.append( train_loss)    \n",
    "    training_acc_vs_epoch.append( train_acc )\n",
    "    \n",
    "    validation_acc_vs_epoch.append(valid_acc)\n",
    "    validation_loss_vs_epoch.append(valid_loss)\n",
    "    \n",
    "    # It saves the model if the validation loss has decreased\n",
    "    if len(validation_loss_vs_epoch)==1 or validation_loss_vs_epoch[-2] > validation_loss_vs_epoch[-1]:\n",
    "        torch.save(net.state_dict(), 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7090e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(8,3))\n",
    "\n",
    "ax[0].plot(training_loss_vs_epoch,label='training')\n",
    "ax[0].plot(validation_loss_vs_epoch,label='validation')\n",
    "\n",
    "ax[1].plot(training_acc_vs_epoch)\n",
    "ax[1].plot(validation_acc_vs_epoch)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af196cd8",
   "metadata": {},
   "source": [
    "### Bonus part\n",
    "\n",
    "As you so the result is not so exciting, a lot of overtraining.\n",
    "\n",
    "Try to rewrite the dataloader in a way that every image gets a random rotation. Then, retrain the network. Hopefully you will get a better result. Do you know why????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(self.filelist[443])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.RandomRotation(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

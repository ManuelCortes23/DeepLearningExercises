{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc33973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e41318",
   "metadata": {},
   "source": [
    "## Homework 2, part 1\n",
    "\n",
    "We build a CNN to classify the galaxies.\n",
    "\n",
    "Goal: 75% or more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d833cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/apl6g5g9svhnfyg/Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training_data = 'Dataset/train/'\n",
    "path_to_validation_data = 'Dataset/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4183a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb89a6e",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "Reuse the same as HW1, but make sure that the shape is (3, 69, 69). This because pretrained models have been trained on color images that have three channels (R,G,B). We need our input to match thath, at least in it's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d5806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of torch repeating an array\n",
    "\n",
    "some_tensor = torch.rand(1,69,69)\n",
    "print(some_tensor.shape)\n",
    "some_tensor = some_tensor.repeat(3,1,1)\n",
    "print(some_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a4e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds = CustomDataset(path_to_training_data,transform=True)\n",
    "validation_ds = CustomDataset(path_to_validation_data)\n",
    "\n",
    "some_random_idx = 2\n",
    "x,y = training_ds[some_random_idx]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_ds,batch_size = 300,shuffle=True)\n",
    "valid_dataloader = DataLoader(validation_ds,batch_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e671af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that you are getting the right dimensions - (Batch size, 3, 69,69)\n",
    "\n",
    "for x,y in training_dataloader:\n",
    "    print(x.shape,y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4387d1a",
   "metadata": {},
   "source": [
    "### Download the pre-trained model\n",
    "\n",
    "From the list https://pytorch.org/vision/stable/models.html, get any pretrained models you want.\n",
    "\n",
    "I show you vgg11 for example (but you can use alexnet or resnet also)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0ac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "pretrained_model = models.vgg11(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43561274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the internal structure..\n",
    "\n",
    "# features (use a Sequential model) -- try to understand what each layer does\n",
    "# classifier (returns an array of 1000, it's a simply FC network)\n",
    "# avgpool allows you to use this with any image size, simply rescale the input to a preffered size\n",
    "\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pretrained models have an output shape that matches the number of classes they were trained on\n",
    "\n",
    "pretrained_model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf313f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output size of the features layer.. after flattening it, this will be the input for the classifier\n",
    "pretrained_model.features(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d232e5",
   "metadata": {},
   "source": [
    "### The model\n",
    "\n",
    "You have to build a model that has the same feature structure, but a different classifier. In fact out output should be size 10, since we have only 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d297319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should get (batch size, 10)\n",
    "net(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac23cc",
   "metadata": {},
   "source": [
    "Now, we copy the feature weights from the pretrained model.\n",
    "\n",
    "If you change one of the layer in the feature part, this command won't work (try!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ab23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict is a dictionary containing every weight in every layer\n",
    "# we want to copy only the feature part\n",
    "\n",
    "pretrained_dict = pretrained_model.state_dict()\n",
    "state_dict = net.state_dict()\n",
    "\n",
    "for key in state_dict.keys():\n",
    "    if 'features' not in key:\n",
    "        continue\n",
    "    if key in pretrained_dict.keys():\n",
    "        state_dict[key] = pretrained_dict[key]\n",
    "\n",
    "net.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b463a341",
   "metadata": {},
   "source": [
    "## Training and validation\n",
    "\n",
    "Same code as homework 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3f9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_and_loss(dataloader,net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    net.eval()\n",
    "    \n",
    "    n_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dataloader:\n",
    "            n_batches+=1\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "                y = y.cuda()\n",
    "            pred = net(x)\n",
    "            \n",
    "            loss+= loss_func(pred,y).item()\n",
    "            \n",
    "            pred = torch.argmax(pred,dim=1)\n",
    "\n",
    "            correct+=len(torch.where(pred==y)[0])\n",
    "            total+=len(y)\n",
    "    loss = loss/n_batches      \n",
    "    return correct/total, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65fe6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42d748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "training_loss_vs_epoch = []\n",
    "validation_loss_vs_epoch = []\n",
    "\n",
    "training_acc_vs_epoch = []\n",
    "validation_acc_vs_epoch = []\n",
    "\n",
    "pbar = tqdm( range(n_epochs) )\n",
    "\n",
    "for epoch in pbar:\n",
    "    \n",
    "    if len(validation_loss_vs_epoch) > 1:\n",
    "        print('epoch',epoch,' val acc:'+'{0:.5f}'.format(validation_acc_vs_epoch[-1])+\n",
    "              ', train acc:'+'{0:.5f}'.format(training_acc_vs_epoch[-1]))\n",
    "    \n",
    "    net.train() # put the net into \"training mode\"\n",
    "    \n",
    "    for x,y in training_dataloader:\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        pred = net(x)\n",
    "        loss = loss_func(pred,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    net.eval() #put the net into evaluation mode\n",
    "    train_acc, train_loss = compute_accuracy_and_loss(training_dataloader,net)\n",
    "    valid_acc, valid_loss =  compute_accuracy_and_loss(valid_dataloader,net)\n",
    "         \n",
    "    training_loss_vs_epoch.append(train_loss)    \n",
    "    training_acc_vs_epoch.append( train_acc )\n",
    "    \n",
    "    validation_acc_vs_epoch.append(valid_acc)\n",
    "    \n",
    "    validation_loss_vs_epoch.append(valid_loss)\n",
    "    if len(validation_loss_vs_epoch)==1 or validation_loss_vs_epoch[-2] > validation_loss_vs_epoch[-1]:\n",
    "        torch.save(net.state_dict(), 'trained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(8,3))\n",
    "\n",
    "ax[0].plot(training_loss_vs_epoch,label='training')\n",
    "ax[0].plot(validation_loss_vs_epoch,label='validation')\n",
    "\n",
    "ax[1].plot(training_acc_vs_epoch)\n",
    "ax[1].plot(validation_acc_vs_epoch)\n",
    "\n",
    "ax[0].set_ylabel('loss')\n",
    "ax[1].set_ylabel('accuracy')\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36f73c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
